{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54OnBoRv2Arr",
        "outputId": "b88fc75b-cd91-4fd1-9a6b-b4a3caf749c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "SySiJgSX_NEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dccb385-2414-4ee1-dfce-c2a32f884668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2EWemBn_ps1",
        "outputId": "6d6a0385-09c9-405c-dca3-9bf8ec169045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-multipart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOxxG1Nc__f8",
        "outputId": "db083ac2-1b68-42b9-9267-6d00355a413c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-multipart\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: python-multipart\n",
            "Successfully installed python-multipart-0.0.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uvicorn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7ZqvyCmBDd6",
        "outputId": "25bd92c5-7293-4431-e899-de7b47030bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn\n",
            "Successfully installed uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHxHq1dn17Ax",
        "outputId": "b5f36217-bbe4-4648-c68e-8e1831b7f3ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.10-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading fastapi-0.115.10-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: starlette, fastapi\n",
            "Successfully installed fastapi-0.115.10 starlette-0.46.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWcds-b_-DqW",
        "outputId": "132458e3-1f0e-4d23-88f9-dc71c23b30b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-24' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 579, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.6.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.6.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastAPI running at https://059d-34-139-227-224.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [337]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     2409:40c1:3a:53eb:1502:9818:3fd8:f7bd:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2409:40c1:3a:53eb:1502:9818:3fd8:f7bd:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     2409:40c1:3a:53eb:1502:9818:3fd8:f7bd:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2409:40c1:3a:53eb:1502:9818:3fd8:f7bd:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     2409:40c1:3a:53eb:1502:9818:3fd8:f7bd:0 - \"POST /predict-breast-cancer/ HTTP/1.1\" 500 Internal Server Error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [337]\n"
          ]
        }
      ],
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import io\n",
        "from PIL import Image\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "import cv2\n",
        "import base64\n",
        "\n",
        "\n",
        "# Fix async issues in Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "app = FastAPI(title=\"AI-Powered Multi-Disease Diagnostic System\")\n",
        "\n",
        "# Load Diabetes Model & Scaler\n",
        "diabetes_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Diabetes/SVM.joblib\"\n",
        "diabetes_dataset_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/diabetes.csv\"\n",
        "\n",
        "diabetes_model = joblib.load(diabetes_model_path)\n",
        "diabetes_df = pd.read_csv(diabetes_dataset_path)\n",
        "diabetes_scaler = StandardScaler()\n",
        "diabetes_scaler.fit(diabetes_df.drop(columns=\"Outcome\", axis=1))\n",
        "\n",
        "\n",
        "# Input Schema for Diabetes Detection\n",
        "class DiabetesInput(BaseModel):\n",
        "    pregnancies: int\n",
        "    glucose: float\n",
        "    blood_pressure: float\n",
        "    skin_thickness: float\n",
        "    insulin: float\n",
        "    bmi: float\n",
        "    diabetes_pedigree: float\n",
        "    age: int\n",
        "\n",
        "\n",
        "# Diabetes Prediction Endpoint\n",
        "@app.post(\"/diabetes/predict\")\n",
        "def predict_diabetes(data: DiabetesInput):\n",
        "    \"\"\"\n",
        "    Predicts whether a person has diabetes.\n",
        "    \"\"\"\n",
        "    input_data = np.array([[data.pregnancies, data.glucose, data.blood_pressure,\n",
        "                            data.skin_thickness, data.insulin, data.bmi,\n",
        "                            data.diabetes_pedigree, data.age]])\n",
        "\n",
        "    input_scaled = diabetes_scaler.transform(input_data)\n",
        "    prediction = diabetes_model.predict(input_scaled)[0]\n",
        "\n",
        "    return {\"prediction\": \"Diabetic\" if prediction == 1 else \"Non-Diabetic\"}\n",
        "\n",
        "\n",
        "# Load Heart Disease Model\n",
        "heart_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Heart/saved_models/Support Vector Machine_model.pkl\"\n",
        "heart_dataset_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/heart.csv\"\n",
        "\n",
        "heart_model = joblib.load(heart_model_path)\n",
        "heart_df = pd.read_csv(heart_dataset_path)\n",
        "heart_scaler = StandardScaler()\n",
        "heart_scaler.fit(heart_df.drop(columns=\"target\", axis=1))\n",
        "\n",
        "\n",
        "# Input Schema for Heart Disease Detection\n",
        "class HeartDiseaseInput(BaseModel):\n",
        "    age: int\n",
        "    sex: int\n",
        "    cp: int\n",
        "    trestbps: float\n",
        "    chol: float\n",
        "    fbs: int\n",
        "    restecg: int\n",
        "    thalach: float\n",
        "    exang: int\n",
        "    oldpeak: float\n",
        "    slope: int\n",
        "    ca: int\n",
        "    thal: int\n",
        "\n",
        "\n",
        "# Heart Disease Prediction Endpoint\n",
        "@app.post(\"/heart_disease/predict\")\n",
        "def predict_heart_disease(data: HeartDiseaseInput):\n",
        "    \"\"\"\n",
        "    Predicts whether a person has heart disease.\n",
        "    \"\"\"\n",
        "    input_data = np.array([[data.age, data.sex, data.cp, data.trestbps, data.chol,\n",
        "                            data.fbs, data.restecg, data.thalach, data.exang, data.oldpeak,\n",
        "                            data.slope, data.ca, data.thal]])\n",
        "\n",
        "    input_scaled = heart_scaler.transform(input_data)\n",
        "    prediction = heart_model.predict(input_scaled)[0]\n",
        "\n",
        "    return {\"prediction\": \"Heart Disease Detected\" if prediction == 1 else \"No Heart Disease\"}\n",
        "\n",
        "\n",
        "# Load Parkinson’s Disease Model & Scaler\n",
        "parkinsons_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Parkinsons/New_Updated_Models/SVM_model.joblib\"\n",
        "parkinsons_scaler_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Parkinsons/New_Updated_Models/scaler.joblib\"\n",
        "\n",
        "parkinsons_model = joblib.load(parkinsons_model_path)\n",
        "parkinsons_scaler = joblib.load(parkinsons_scaler_path)\n",
        "\n",
        "\n",
        "# Input Schema for Parkinson’s Disease Detection\n",
        "class ParkinsonsInput(BaseModel):\n",
        "    MDVP_Fo: float\n",
        "    MDVP_Fhi: float\n",
        "    MDVP_Flo: float\n",
        "    MDVP_Jitter_percent: float\n",
        "    MDVP_Jitter_Abs: float\n",
        "    MDVP_RAP: float\n",
        "    MDVP_PPQ: float\n",
        "    Jitter_DDP: float\n",
        "    MDVP_Shimmer: float\n",
        "    MDVP_Shimmer_dB: float\n",
        "    Shimmer_APQ3: float\n",
        "    Shimmer_APQ5: float\n",
        "    MDVP_APQ: float\n",
        "    Shimmer_DDA: float\n",
        "    NHR: float\n",
        "    HNR: float\n",
        "    RPDE: float\n",
        "    DFA: float\n",
        "    spread1: float\n",
        "    spread2: float\n",
        "    D2: float\n",
        "    PPE: float\n",
        "\n",
        "\n",
        "# Parkinson’s Disease Prediction Endpoint\n",
        "@app.post(\"/parkinsons/predict\")\n",
        "def predict_parkinsons(data: ParkinsonsInput):\n",
        "    \"\"\"\n",
        "    Predicts whether a person has Parkinson's disease.\n",
        "    \"\"\"\n",
        "    input_data = np.array([[data.MDVP_Fo, data.MDVP_Fhi, data.MDVP_Flo, data.MDVP_Jitter_percent,\n",
        "                            data.MDVP_Jitter_Abs, data.MDVP_RAP, data.MDVP_PPQ, data.Jitter_DDP,\n",
        "                            data.MDVP_Shimmer, data.MDVP_Shimmer_dB, data.Shimmer_APQ3, data.Shimmer_APQ5,\n",
        "                            data.MDVP_APQ, data.Shimmer_DDA, data.NHR, data.HNR, data.RPDE,\n",
        "                            data.DFA, data.spread1, data.spread2, data.D2, data.PPE]])\n",
        "\n",
        "    input_scaled = parkinsons_scaler.transform(input_data)\n",
        "    prediction = parkinsons_model.predict(input_scaled)[0]\n",
        "    probability = parkinsons_model.predict_proba(input_scaled)[:, 1][0]\n",
        "\n",
        "    return {\n",
        "        \"prediction\": \"Parkinson's Detected\" if prediction == 1 else \"No Parkinson's\",\n",
        "        \"probability\": probability\n",
        "    }\n",
        "\n",
        "\n",
        "# Load Breast Cancer Detection Model\n",
        "breast_cancer_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Breast Cancer Detection/Breast Cancer Detection DenseNet121/Breast_Cancer_Detection_DenseNet121.h5\"\n",
        "breast_cancer_model = keras.models.load_model(breast_cancer_model_path)\n",
        "breast_cancer_labels = {0: 'benign', 1: 'malignant', 2: 'normal'}\n",
        "\n",
        "\n",
        "class Base64ImageRequest(BaseModel):\n",
        "    \"\"\"Request model to accept a Base64 string.\"\"\"\n",
        "    base64_image: str\n",
        "\n",
        "def base64_to_array(base64_string):\n",
        "    \"\"\"Convert a Base64 string to a NumPy image array.\"\"\"\n",
        "    try:\n",
        "        image_bytes = base64.b64decode(base64_string)  # Decode Base64 to bytes\n",
        "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")  # Convert to PIL image\n",
        "        image = image.resize((256, 256))  # Resize for model input\n",
        "        image_array = np.array(image) / 255.0  # Normalize pixel values\n",
        "        image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
        "        return image_array\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Invalid image data: {str(e)}\")\n",
        "\n",
        "@app.post(\"/predict-breast-cancer/\")\n",
        "async def predict_cancer(request: Base64ImageRequest):\n",
        "    \"\"\"Accepts a Base64 image string, decodes it, and predicts breast cancer.\"\"\"\n",
        "    try:\n",
        "        # Convert Base64 to NumPy array\n",
        "        img_array = base64_to_array(request.base64_image)\n",
        "\n",
        "        # Make a prediction\n",
        "        prediction = breast_cancer_model.predict(img_array)\n",
        "        predicted_label_index = np.argmax(prediction)\n",
        "        predicted_label = breast_cancer_labels.get(predicted_label_index, \"Unknown\")\n",
        "        confidence = np.max(prediction) * 100  # Confidence score in percentage\n",
        "\n",
        "        return {\n",
        "            \"predicted_class\": predicted_label,\n",
        "            \"confidence\": f\"{confidence:.2f}%\",\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# Load Tuberculosis Detection Model\n",
        "tb_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Tuberculosis Classification/Tuberculosis Classification DenseNet/Tuberculosis_detection_DenseNet169.h5\"\n",
        "tb_model = load_model(tb_model_path)\n",
        "tb_labels = {0: \"Normal\", 1: \"Tuberculosis\"}\n",
        "\n",
        "\n",
        "class Base64ImageRequest(BaseModel):\n",
        "    \"\"\"Request model to accept a Base64 string.\"\"\"\n",
        "    base64_image: str\n",
        "\n",
        "def base64_to_array(base64_string):\n",
        "    \"\"\"Convert a Base64 string to a NumPy image array.\"\"\"\n",
        "    try:\n",
        "        image_bytes = base64.b64decode(base64_string)  # Decode Base64 to bytes\n",
        "        img = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")  # Convert to PIL image\n",
        "        img = img.resize((224, 224))  # Resize for model input\n",
        "        img_array = image.img_to_array(img)  # Convert to NumPy array\n",
        "        img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize pixel values\n",
        "        return img_array\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Invalid image data: {str(e)}\")\n",
        "\n",
        "@app.post(\"/tuberculosis/predict\")\n",
        "async def predict_tuberculosis(request: Base64ImageRequest):\n",
        "    \"\"\"Accepts a Base64 image string, decodes it, and predicts tuberculosis.\"\"\"\n",
        "    try:\n",
        "        # Convert Base64 to NumPy array\n",
        "        img_array = base64_to_array(request.base64_image)\n",
        "\n",
        "        # Make a prediction\n",
        "        y_pred = tb_model.predict(img_array)\n",
        "        predicted_label_index = np.argmax(y_pred, axis=1)[0]\n",
        "        predicted_label = tb_labels.get(predicted_label_index, \"Unknown\")\n",
        "        confidence = np.max(y_pred) * 100  # Confidence score in percentage\n",
        "\n",
        "        return {\n",
        "            \"prediction\": predicted_label,\n",
        "            \"confidence\": f\"{confidence:.2f}%\",\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "\n",
        "# Load Brain Tumor Detection Model (VGG16)\n",
        "brain_tumor_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Brain Tumor Detection/Brain Tumor VGG16/Brain_tumor_VGG16.h5\"\n",
        "brain_tumor_model = load_model(brain_tumor_model_path, compile=False)\n",
        "brain_tumor_labels = ['Glioma Tumor', 'Meningioma Tumor', 'No Tumor', 'Pituitary Tumor']\n",
        "\n",
        "\n",
        "class Base64ImageRequest(BaseModel):\n",
        "    \"\"\"Request model to accept a Base64 image string.\"\"\"\n",
        "    base64_image: str\n",
        "\n",
        "def base64_to_array(base64_string):\n",
        "    \"\"\"Convert a Base64 string to a NumPy image array.\"\"\"\n",
        "    try:\n",
        "        image_bytes = base64.b64decode(base64_string)  # Decode Base64 to bytes\n",
        "        img = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")  # Convert to PIL image\n",
        "        img = img.resize((224, 224))  # Resize for model input\n",
        "        img_array = image.img_to_array(img)  # Convert to NumPy array\n",
        "        img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize pixel values\n",
        "        return img_array\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Invalid image data: {str(e)}\")\n",
        "\n",
        "@app.post(\"/brain_tumor/predict\")\n",
        "async def predict_brain_tumor(request: Base64ImageRequest):\n",
        "    \"\"\"Accepts a Base64 image string, decodes it, and predicts brain tumor presence.\"\"\"\n",
        "    try:\n",
        "        # Convert Base64 to NumPy array\n",
        "        img_array = base64_to_array(request.base64_image)\n",
        "\n",
        "        # Make a prediction\n",
        "        predictions = brain_tumor_model.predict(img_array)\n",
        "        predicted_class = np.argmax(predictions)\n",
        "        confidence = np.max(predictions) * 100  # Confidence score in percentage\n",
        "\n",
        "        return {\n",
        "            \"prediction\": brain_tumor_labels[predicted_class],\n",
        "            \"confidence\": f\"{confidence:.2f}%\",\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "\n",
        "ngrok.set_auth_token(\"2tiWVuWIuwHqZqawlF14vNsjl7a_3YLB1fXP8W7gTcSMU4LFp\")\n",
        "# Start the FastAPI server in the background\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print(f\"FastAPI running at {ngrok_tunnel.public_url}\")\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import io\n",
        "from PIL import Image\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "import cv2\n",
        "import base64\n",
        "\n",
        "# Fix async issues in Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "app = FastAPI(title=\"AI-Powered Multi-Disease Diagnostic System\")\n",
        "\n",
        "#################################\n",
        "# DIABETES MODEL AND ENDPOINT\n",
        "#################################\n",
        "diabetes_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Diabetes/SVM.joblib\"\n",
        "diabetes_dataset_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/diabetes.csv\"\n",
        "\n",
        "diabetes_model = joblib.load(diabetes_model_path)\n",
        "diabetes_df = pd.read_csv(diabetes_dataset_path)\n",
        "diabetes_scaler = StandardScaler()\n",
        "diabetes_scaler.fit(diabetes_df.drop(columns=\"Outcome\", axis=1))\n",
        "\n",
        "class DiabetesInput(BaseModel):\n",
        "    pregnancies: int\n",
        "    glucose: float\n",
        "    blood_pressure: float\n",
        "    skin_thickness: float\n",
        "    insulin: float\n",
        "    bmi: float\n",
        "    diabetes_pedigree: float\n",
        "    age: int\n",
        "\n",
        "@app.post(\"/diabetes/predict\")\n",
        "def predict_diabetes(data: DiabetesInput):\n",
        "    input_data = np.array([[data.pregnancies, data.glucose, data.blood_pressure,\n",
        "                            data.skin_thickness, data.insulin, data.bmi,\n",
        "                            data.diabetes_pedigree, data.age]])\n",
        "    input_scaled = diabetes_scaler.transform(input_data)\n",
        "    prediction = diabetes_model.predict(input_scaled)[0]\n",
        "    return {\"prediction\": \"Diabetic\" if prediction == 1 else \"Non-Diabetic\"}\n",
        "\n",
        "#################################\n",
        "# HEART DISEASE MODEL AND ENDPOINT\n",
        "#################################\n",
        "heart_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Heart/saved_models/Support Vector Machine_model.pkl\"\n",
        "heart_dataset_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/heart.csv\"\n",
        "\n",
        "heart_model = joblib.load(heart_model_path)\n",
        "heart_df = pd.read_csv(heart_dataset_path)\n",
        "heart_scaler = StandardScaler()\n",
        "heart_scaler.fit(heart_df.drop(columns=\"target\", axis=1))\n",
        "\n",
        "class HeartDiseaseInput(BaseModel):\n",
        "    age: int\n",
        "    sex: int\n",
        "    cp: int\n",
        "    trestbps: float\n",
        "    chol: float\n",
        "    fbs: int\n",
        "    restecg: int\n",
        "    thalach: float\n",
        "    exang: int\n",
        "    oldpeak: float\n",
        "    slope: int\n",
        "    ca: int\n",
        "    thal: int\n",
        "\n",
        "@app.post(\"/heart_disease/predict\")\n",
        "def predict_heart_disease(data: HeartDiseaseInput):\n",
        "    input_data = np.array([[data.age, data.sex, data.cp, data.trestbps, data.chol,\n",
        "                            data.fbs, data.restecg, data.thalach, data.exang, data.oldpeak,\n",
        "                            data.slope, data.ca, data.thal]])\n",
        "    input_scaled = heart_scaler.transform(input_data)\n",
        "    prediction = heart_model.predict(input_scaled)[0]\n",
        "    return {\"prediction\": \"Heart Disease Detected\" if prediction == 1 else \"No Heart Disease\"}\n",
        "\n",
        "#################################\n",
        "# PARKINSON'S DISEASE MODEL AND ENDPOINT\n",
        "#################################\n",
        "parkinsons_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Parkinsons/New_Updated_Models/SVM_model.joblib\"\n",
        "parkinsons_scaler_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Parkinsons/New_Updated_Models/scaler.joblib\"\n",
        "\n",
        "parkinsons_model = joblib.load(parkinsons_model_path)\n",
        "parkinsons_scaler = joblib.load(parkinsons_scaler_path)\n",
        "\n",
        "class ParkinsonsInput(BaseModel):\n",
        "    MDVP_Fo: float\n",
        "    MDVP_Fhi: float\n",
        "    MDVP_Flo: float\n",
        "    MDVP_Jitter_percent: float\n",
        "    MDVP_Jitter_Abs: float\n",
        "    MDVP_RAP: float\n",
        "    MDVP_PPQ: float\n",
        "    Jitter_DDP: float\n",
        "    MDVP_Shimmer: float\n",
        "    MDVP_Shimmer_dB: float\n",
        "    Shimmer_APQ3: float\n",
        "    Shimmer_APQ5: float\n",
        "    MDVP_APQ: float\n",
        "    Shimmer_DDA: float\n",
        "    NHR: float\n",
        "    HNR: float\n",
        "    RPDE: float\n",
        "    DFA: float\n",
        "    spread1: float\n",
        "    spread2: float\n",
        "    D2: float\n",
        "    PPE: float\n",
        "\n",
        "@app.post(\"/parkinsons/predict\")\n",
        "def predict_parkinsons(data: ParkinsonsInput):\n",
        "    input_data = np.array([[data.MDVP_Fo, data.MDVP_Fhi, data.MDVP_Flo, data.MDVP_Jitter_percent,\n",
        "                            data.MDVP_Jitter_Abs, data.MDVP_RAP, data.MDVP_PPQ, data.Jitter_DDP,\n",
        "                            data.MDVP_Shimmer, data.MDVP_Shimmer_dB, data.Shimmer_APQ3, data.Shimmer_APQ5,\n",
        "                            data.MDVP_APQ, data.Shimmer_DDA, data.NHR, data.HNR, data.RPDE,\n",
        "                            data.DFA, data.spread1, data.spread2, data.D2, data.PPE]])\n",
        "    input_scaled = parkinsons_scaler.transform(input_data)\n",
        "    prediction = parkinsons_model.predict(input_scaled)[0]\n",
        "    probability = parkinsons_model.predict_proba(input_scaled)[:, 1][0]\n",
        "    return {\n",
        "        \"prediction\": \"Parkinson's Detected\" if prediction == 1 else \"No Parkinson's\",\n",
        "        \"probability\": probability\n",
        "    }\n",
        "\n",
        "#################################\n",
        "# BREAST CANCER DETECTION MODEL AND ENDPOINT\n",
        "#################################\n",
        "breast_cancer_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Breast Cancer Detection/Breast Cancer Detection DenseNet121/Breast_Cancer_Detection_DenseNet121.h5\"\n",
        "breast_cancer_model = keras.models.load_model(breast_cancer_model_path)\n",
        "breast_cancer_labels = {0: 'benign', 1: 'malignant', 2: 'normal'}\n",
        "\n",
        "#################################\n",
        "# TUBERCULOSIS DETECTION MODEL AND ENDPOINT\n",
        "#################################\n",
        "tb_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Tuberculosis Classification/Tuberculosis Classification DenseNet/Tuberculosis_detection_DenseNet169.h5\"\n",
        "tb_model = load_model(tb_model_path)\n",
        "tb_labels = {0: \"Normal\", 1: \"Tuberculosis\"}\n",
        "\n",
        "#################################\n",
        "# BRAIN TUMOR DETECTION MODEL AND ENDPOINT\n",
        "#################################\n",
        "brain_tumor_model_path = \"/content/drive/MyDrive/AI Powered Multi Disease Diagnostic System/Brain Tumor Detection/Brain Tumor VGG16/Brain_tumor_VGG16.h5\"\n",
        "brain_tumor_model = load_model(brain_tumor_model_path, compile=False)\n",
        "brain_tumor_labels = ['Glioma Tumor', 'Meningioma Tumor', 'No Tumor', 'Pituitary Tumor']\n",
        "\n",
        "#################################\n",
        "# UTILITY: BASE64 IMAGE CONVERSION\n",
        "#################################\n",
        "class Base64ImageRequest(BaseModel):\n",
        "    base64_image: str\n",
        "\n",
        "def base64_to_array(base64_string, target_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Convert a Base64 string to a NumPy image array with a given target size.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        image_bytes = base64.b64decode(base64_string)\n",
        "        img = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "        img = img.resize(target_size)\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "        return img_array\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Invalid image data: {str(e)}\")\n",
        "\n",
        "#################################\n",
        "# BREAST CANCER PREDICTION ENDPOINT (256x256 input)\n",
        "#################################\n",
        "@app.post(\"/predict-breast-cancer/\")\n",
        "async def predict_cancer(request: Base64ImageRequest):\n",
        "    try:\n",
        "        img_array = base64_to_array(request.base64_image, target_size=(256, 256))\n",
        "        prediction = breast_cancer_model.predict(img_array)\n",
        "        predicted_label_index = np.argmax(prediction)\n",
        "        predicted_label = breast_cancer_labels.get(predicted_label_index, \"Unknown\")\n",
        "        confidence = np.max(prediction) * 100\n",
        "        return {\n",
        "            \"predicted_class\": predicted_label,\n",
        "            \"confidence\": f\"{confidence:.2f}%\",\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "#################################\n",
        "# TUBERCULOSIS PREDICTION ENDPOINT (224x224 input)\n",
        "#################################\n",
        "@app.post(\"/tuberculosis/predict\")\n",
        "async def predict_tuberculosis(request: Base64ImageRequest):\n",
        "    try:\n",
        "        img_array = base64_to_array(request.base64_image, target_size=(224, 224))\n",
        "        y_pred = tb_model.predict(img_array)\n",
        "        predicted_label_index = np.argmax(y_pred, axis=1)[0]\n",
        "        predicted_label = tb_labels.get(predicted_label_index, \"Unknown\")\n",
        "        confidence = np.max(y_pred) * 100\n",
        "        return {\n",
        "            \"prediction\": predicted_label,\n",
        "            \"confidence\": f\"{confidence:.2f}%\",\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "#################################\n",
        "# BRAIN TUMOR PREDICTION ENDPOINT (224x224 input)\n",
        "#################################\n",
        "@app.post(\"/brain_tumor/predict\")\n",
        "async def predict_brain_tumor(request: Base64ImageRequest):\n",
        "    try:\n",
        "        img_array = base64_to_array(request.base64_image, target_size=(224, 224))\n",
        "        predictions = brain_tumor_model.predict(img_array)\n",
        "        predicted_class = np.argmax(predictions)\n",
        "        confidence = np.max(predictions) * 100\n",
        "        return {\n",
        "            \"prediction\": brain_tumor_labels[predicted_class],\n",
        "            \"confidence\": f\"{confidence:.2f}%\",\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "#################################\n",
        "# NGROK & SERVER SETUP\n",
        "#################################\n",
        "ngrok.set_auth_token(\"2tiWVuWIuwHqZqawlF14vNsjl7a_3YLB1fXP8W7gTcSMU4LFp\")\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print(f\"FastAPI running at {ngrok_tunnel.public_url}\")\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "1KKRDVhZ2Snm",
        "outputId": "9f4ddf5f-63ed-4048-ca04-cd0a6ff9a07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.6.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.6.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "ERROR:pyngrok.process.ngrok:t=2025-03-01T13:44:28+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-03-01T13:44:28+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-03-01T13:44:28+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "CRITICAL:pyngrok.process.ngrok:t=2025-03-01T13:44:28+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-03-01T13:44:28+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context canceled\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-8beb2ea6fd51>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2tiWVuWIuwHqZqawlF14vNsjl7a_3YLB1fXP8W7gTcSMU4LFp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;31m# Start the FastAPI server in the background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m \u001b[0mngrok_tunnel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"FastAPI running at {ngrok_tunnel.public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0muvicorn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.0.0.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    429\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sN-ZT47w8bPR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}